\documentclass[12pt,a4paper]{article}

\usepackage{import}
\import{../Template/}{format.tex}

\newcommand{\topic}{Principle of Data Science}

\begin{document}

\title{\topic}
\begin{titlepage}
    \maketitle
\end{titlepage}

\tableofcontents

\newpage
\begin{abstract}
\noindent
Abstract of this course
\end{abstract}

\newpage
\begin{abstract}
\noindent
Abstract of this course
\end{abstract}

\section{Understanding Data}
\subsection{Visualising Data}
\subsubsection{Histograms}
What are bins in Histogram
\subsubsection{Scatter Plots}
\subsection{Measuring the moments}
\subsubsection{Average}
\subsubsection{Spread}
\subsubsection{Higher Moments}
\subsection{Covariance and Correlation}
\begin{definition}
    {Covariance}
    {V_{x y}={cov}(x, y) =\overline{x y}-\bar{x} \bar{y}
    =\frac{1}{N} \sum_i^N\left(x_i-\bar{x}\right)\left(y_i-\bar{y}\right)}
    {Highly covariance means that one variance tends high when the other high, 
    whereas a highly negative covariance means that one variable tends low while the other tends high. 
    A low magnitude of absolute covariance indicates that two variable are more independent of each other.}
\end{definition}

\begin{definition}
    {Covariance Matrix}
    {\boldsymbol{V}=E\left[(\vec{X}-\vec{\mu})(\vec{X}-\vec{\mu})^{\mathrm{T}}\right]=\left[\begin{array}{cccc}\sigma_1^2 & \rho_{12} \sigma_1 \sigma_2 & \ldots & \rho_{1 n} \sigma_1 \sigma_n \\ \rho_{12} \sigma_1 \sigma_2 & \sigma_2^2 & \ldots & \vdots \\ \vdots & \vdots & \vdots & \vdots \\ \rho_{1 k} \sigma_1 \sigma_n & \ldots & \ldots & \sigma_n^2\end{array}\right]}{}
\end{definition}
\begin{definition}
    {Correlation}
    {\rho(x, y)=\frac{\operatorname{cov}(x, y)}{\sigma_x \sigma_y}=\frac{\overline{x y}-\bar{x} \bar{y}}{\sigma_x \sigma_y}}
    {Correlation is just covariance normalised by the standard deviation product. It is also the sqaure root of $R^2$}
\end{definition}
\subsection{Learning from Data}
\subsubsection{Typical Structure of Data}
Common data structure include NumPy array or Pandas dataframes. \\
Note that we have \textit{features} and \textit{events} for a set of data. In pandas, the features correspond to columns whereas event correspond to rows.
\subsubsection{Exploiting correlation in data}
See Machine Learning for more information.

- Recall: true positive rate. Sometimes also called signal efficiency or sensitivity. The fraction of all positive or signal events that are correctly classified:
$$
T P R=\frac{T P}{T P+F N} .
$$
- Specificity: true negative rate. Sometimes also called background efficiency. The fraction of all negative or background events that are correctly classified:
$$
T N R=\frac{T N}{T N+F P} .
$$
- False positive rate. The fraction of all negative or background events that incorrectly classified:
$$
F P R=\frac{F P}{F P+T N} .
$$
- False negative rate. The fraction of all positive or signal events that incorrectly classified:
$$
F N R=\frac{F N}{F N+T P}
$$
- Note the relationships between TPR and FNR, as well as TNR and FPR:
$$
\begin{aligned}
& T P R+F N R=\frac{T P}{T P+F N}+\frac{F N}{F N+T P}=\frac{T P+F N}{T P+F N}=1, \\
& T N R+F P R=\frac{T N}{T N+F P}+\frac{F N}{F P+T N}=\frac{T N+F P}{T N+F P}=1,
\end{aligned}
$$
so that $F P R=1-T N R, F N R=1-T P R$.

\subsubsection{Performance criteria and metrics}
\begin{itemize}
    \item True positive (TP). Correct prediction of positive or signal outcome.
    \item False positive (FP). Incorrect prediction of positive or signal outcome.
    \item True negative (TN). Correct prediction of negative or background outcome.
    \item False negative (FN). Incorrect prediction of negative or background outcome.
    \item All positive or signal events are given by $P=T P+F N$.
    \item All negative or background events are given by $N=T N+F P$.
    \item All events classified as positive or signal-like are given by $C_P=T P+F P$.
    \item All events classified as negative or signal-like are given by $C_N=T N+F N$.
    \item Recall(or signal efficiency in particle physics): true positive rate. Sometimes also called signal efficiency or sensitivity. The fraction of all positive or signal events that are correctly classified:
    $$
    T P R=\frac{T P}{T P+F N} .
    $$
    \item Specificity(or ): true negative rate. Sometimes also called background efficiency. The fraction of all negative or background events that are correctly classified:
    $$
    T N R=\frac{T N}{T N+F P} .
    $$
    
    \item False positive rate. The fraction of all negative or background events that incorrectly classified:
    $$
    F P R=\frac{F P}{F P+T N} .
    $$
    \item False negative rate. The fraction of all positive or signal events that incorrectly classified:
    $$
    F N R=\frac{F N}{F N+T P}
    $$
    \item Note the relationships between TPR and FNR, as well as TNR and FPR:
    $$
    \begin{aligned}
    & T P R+F N R=\frac{T P}{T P+F N}+\frac{F N}{F N+T P}=\frac{T P+F N}{T P+F N}=1, \\
    & T N R+F P R=\frac{T N}{T N+F P}+\frac{F N}{F P+T N}=\frac{T N+F P}{T N+F P}=1,
    \end{aligned}
    $$
    \item Accuracy. The fraction of all events that correctly classified:
    $$
    \alpha=\frac{T P+T N}{P+N} .
    $$
    \item Error rate. The fraction of all events that are incorrectly classified:
    $$
    \varepsilon=\frac{F P+F N}{P+N} .
    $$
    \item Purity. The fraction of all events classified positively that are correctly classified:
    $$
    \rho_P=\frac{T P}{T P+F P} \quad \text { and } \quad \rho_N=\frac{T N}{T N+F N} .
    $$
    \item Significance. For a counting experiment quantifies the statistical significance:
    $$
    \sigma=\frac{T P}{\sqrt{T P+F P}} .
    $$
    \item Signal-to-noise, sometimes also called signal-to-background ratio:
    $$
    S N R=\frac{T P}{F P} .
    $$
    \item F-score, sometimes also called F-measure:
    $$
    F=2 \frac{\text { precision } \times \text { recall }}{\text { precisoin }+ \text { recall }}=\frac{2 T P R}{2 T P R+F P R+F N R} .
    $$
\end{itemize}

Concepts of Type I and Type II errors.\\
Usually, one algorithm will prioritise one thing at the cost of the other, for example maximise TPR will results in a high FPR as well.\\
A good metric to optimise is ROC (receiver-operating-characteristic), which is the curve in FPR vs TPF graph, and we would like to push the curve to the top left.
\subsubsection{Data challeneges}


\section{Probability}
\subsection{Definition of Probability}
    \subsubsection{Frequentist}
        Frequentist
        - The true probability in practise is never obtainable (because we cannot perform infinite experiments). We can only estimate the probability given the sample size we have. However, if it always possible to perform more experiments then we can keep doing so until we reach the desired accuracy (and any accuracy is in principle achievable).
        - Frequentist probability can only be applied to repeatable experiments. For example I cannot use it to determine the probability it will rain the day after tomorrow. I need a system in which I can keep relevent conditions stable to perform repeatable experiments.
        - One does not need to have any prior beliefs about outcomes, the probability is purely determined from observations.

    \subsubsection{}
        Baysian
    Finetti's coherent bet:
    \begin{itemize}
        \item 1. If you are willing to bet on the outcome of a random experiment, then you should be willing to bet on the outcome of any exchangeable random experiment.
    \end{itemize}

%     Reinforcement learning: keeping learning from new data from enviroment
% Semi_supervise: 

% Generative: less data, no missing values, continuous model to 
% Discriminative : more data  ??? 

\subsection{Property of Probability}
    Property of probability is based on Kolmogorov's axioms
    \begin{itemize}
        \item Addition
        \item Conditional Probability
        \item Independence
            A and B are independent if P(A, B) = P(A)P(B)

    \end{itemize}
    \subsubsection{Monty Hall Problem}
    Check Example Sheet 1

\subsection{Probability mass/density Function}
    $P(X)$ to denote probability mass function (discrete probability)
    $p(X)$ to denote probability density function (continuous probability)

\subsection{Change of variables}
    $$X ~ f(x)$$
    Denotes that X is distributed like f(x)
    $$y = h(x)$$
    Denotes that y is a function of X
    To change variables, probability must be conserved
    Functions are invertible 

    ** Jacobian Matrix
\subsubsection{The cumulative distribution}

\begin{definition}
    {Cumulative distribution function}
    {F(X)=\int_{-\infty}^X f\left(X^{\prime}\right) d X^{\prime}}
    {which is the integrated p.d.f.}
\end{definition}\\
It is defined so that
$$
\begin{aligned}
& F\left(X_{\min }\right)=0, \\
& F\left(X_{\max }\right)=1,
\end{aligned}
$$

with some very useful properties
$$
\begin{aligned}
& P\left(X<X^{\prime}\right)=\int_{X_{\min }}^{X^{\prime}} f(X) d X=F\left(X^{\prime}\right), \\
& P\left(X^{\prime}<X<X^{\prime \prime}\right)=\int_{X^{\prime}}^{X^{\prime \prime}} f(X) d X=F\left(X^{\prime \prime}\right)-F(X) .
\end{aligned}
$$

The integral of p.d.f is the difference in c.d.f.
\subsubsection{The Joint, Marginal and conditional distribution}
independent indicates uncorrelated ?
not correlated does not indicate independence (coreelated means linearly-independent, they can have a quadratic relationship)

Correlation means linear relationships\\
\begin{definition}
    {Joint Probability}
    {f(X, Y)=g(X) h(Y)}
    {}
\end{definition}
\begin{definition}
    {Marginal Distribution}
    {g(X)=\int f(X, Y) d Y \text{ the marginal distribution in }X\\ 
     h(Y)=\int f(X, Y) d X \text{ the marginal distribution in }Y.}
    {}
\end{definition}
\begin{definition}
    {Conditional distribution}
    {g(X \mid Y)=\frac{f(X, Y)}{h(Y)}=\frac{f(X, Y)}{\int f(X, Y) d X} the probability of X given Y,\\
    h(Y \mid X)=\frac{f(X, Y)}{g(X)}=\frac{f(X, Y)}{\int f(X, Y) d Y} the probability of Y given X.}
    {}
\end{definition}
\subsubsection{Bayes' theorem for continuous variables}
\begin{definition}
    {Bayes' theorem}
    {p(\theta \mid X)=\frac{p(X \mid \theta) p(\theta)}{p(X)}=\frac{p(X \mid \theta) p(\theta)}{\int p(X \mid \theta) p(\theta) d \theta}}
    {The terms in the equation
    \begin{itemize}
        \item $p(\theta \mid X)$ - the \textit{posterior distribution} - our probability distribution for the parameter $\theta$ given the data we have observed $X$.
        50
        \item $p(X \mid \theta)$ - the \textit{likelihood function} - the likelihood we observe the data $X$ given a particular value of $\theta$. This is of vital importance across all of statistics and machine learning. We will discuss the likelihood in much more detail in Sec. 3.2.
        \item $p(\theta)$ - the \textit{prior distribution} - encompassing our prior beliefs about $\theta$, this can be based on previous measurements, previous beliefs or indeed be flat (although note that a change of variables or basis will not necessarily maintain flatness). The prior influences the outcome of Bayesian inference, which can be seen as an advatange and a disadvantage. I will leave discussion of priors to the other stats course.
        \item $p(X)$ - the \textit{evidence} - this is just a normalisation factor that ensures the posterior is a p.d.f.. For Bayesian inference the evidence can often be ignored as the posterior is proportional to the numerator of (2.40). However, the evidence can be quite a useful quantity for goodness of fit tests. I will leave discussion of the evidence to the other stats course.
    \end{itemize}.
    }
\end{definition}
\subsection{Properties of Distributions}
\subsubsection{Expextation, mean adn variance}
\begin{definition}
    {Expectation}
    {E[g(X)]=\int g(X) f(X) d X}
    {Expertation is a linear operator, is the true mean of the distribution}
\end{definition}\\

\begin{definition}
    {Variance}
    {
    V(x)=\sigma^2 &=E\left[(X-\mu)^2\right] \\
    &=E\left[X^2-2 \mu X+\mu^2\right] \\
    &=E\left[X^2\right]-\mu^2 \\
    &=\sigma^2
    }
    {}
\end{definition}\\
We can also define the moments of the distribution using expectation values. The moments are defined as
$$
\begin{array}{ll}
\mu_{\ell}=E\left[X^{\ell}\right] & \text { the } \ell^{\text {th }} \text { algebraic moment } \\
\alpha_{\ell}=E\left[(X-E[X])^{\ell}\right] & \text { the } \ell^{\text {th }} \text { moment about the mean. }
\end{array}
$$
In our notation the mean is $\mu=\mu_1$ and the variance is $\sigma^2=\alpha_2$. The skew is $\gamma_1=\sqrt{\beta_1}=$ $\mu_3 / \mu_2^{3 / 2}$. The kurtosis is $\gamma_2=\beta_2-3=\mu_4 / \mu_2^2-3$.
\subsubsection{Covariance and Correlation}
We can also define the covariance between two random variables $X$ and $Y$,
$$
V(X, Y)=E\left[\left(X-\mu_X\right)\left(Y-\mu_Y\right)\right]=E[X Y]-E[X] E[Y],
$$
and then the correlation
$$
\rho(X, Y)=\frac{V(X, Y)}{\sigma_X \sigma_Y}
$$
Note the math behind derivation.
\paragraph{Example}
Assume $x \sim f(x)=N e^{-x^2}$\\
Find $N \Rightarrow $

$$
\int_{-\infty}^{\infty} f(x) d x=1 \Rightarrow N \Rightarrow \frac{1}{\sqrt{\pi}}$$\\
Find $E[x] \Rightarrow $

$$\int_{-\infty}^{\infty} x f(x) d x=0$$ as its add function.\\
Find $E\left[(x-\mu)^2\right] \Rightarrow$

$$E\left[x^2\right]-(E[x])^2$$

$$
E\left[x^{2}\right]=\int_{-\infty}^{\infty} x^2 f(x) d x \quad \Rightarrow \quad \sigma^2=\frac{1}{2}
$$
To get $\sigma=1$.
$f(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} \rightarrow$ stanclond model
shift $x$ by $\mu$ and scale by $\frac{1}{\sigma}$. ie. $z=\frac{x-\mu}{\sigma}$
$\Rightarrow$ Now Model
$$
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}
$$
$$
\frac{1}{N}=\sigma \sqrt{2 \pi}, \text { Mean }=\mu \quad \text { variance }=\sigma^2
$$
\subsubsection{The characteristic function}
\begin{definition}
    {characteristic function}
    {\varphi(t)=E\left[e^{i t X}\right]=\int_{-\infty}^{\infty} e^{i t X} f(X) d X}
    {which means that $f(X)$ is completely defined by the characteristic functions
    $$
    f(X)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} \varphi(t) e^{-i X t} d t
    $$
    The usefulness of the characteristic function is shown in proof for central limit theorem, or algebraic moments
    $$
    \mu_n=E\left[X^n\right]=\int_{-\infty}^{\infty} X^n f(X) d X
    $$
    which can be obtained by differentiating the characteristic function $n$ times at point $t=0$
    $$
    \varphi_n(t)=\frac{d^n \varphi(t)}{d t^n}=i^n \int_{-\infty}^{\infty} x^n e^{i t X} f(X) d X
    $$
    such that
    $\varphi_n(0)=i^n \mu_n$.
    }
\end{definition}
\subsection{Common Distribution}
p.d.f.s depend on one r.v.s. $x$ and parameters $\theta$, write as
$$
p(x;\theta)
$$
where ; distinguish rvs and parameters
\subsubsection{Binomial Distribution}
\begin{definition}
    {Binomial distribution}
    {P(k ; p, n)=\frac{n !}{k !(n-k) !} p^k(1-p)^{n-k}}
    {given $n$ trials,$p(sucess) = p$, $p(fail)= q = 1- p$ and the total probability of k triads are success is 
    $$
    p^k(1-p)^{n-k}
    $$}
\end{definition}
\subsubsection{Poisson Distribution}
\begin{definition}
    {Poisson distribution}
    {P(k, \lambda)=\frac{e^{-\lambda} \lambda^k}{k !}}
    {}
\end{definition}
Derivation of Poisson Distribution from binomial
$$
P(k ; \lambda / n, n)=\left(\frac{\lambda}{n}\right)^k\left(1-\frac{\lambda}{n}\right)^{n-k} \frac{n !}{k !(n-k) !}
$$
Mean of Poisson Distribution

Variance of Poisson Distribution

\subsubsection{Normal Distribution}
\begin{definition}
    {Normal Distribution}{}{}
\end{definition}
It can be shifted by $\mu$ and scale by $\sigma$
$$
p(x;\mu, \sigma)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}
$$

$$
f(x) = \phi(z) = \frac{1}{\sqrt{2\pi}}\int^z_{-\infty}{e^{-z^2/2} dz}
$$

p-value is the probability values
\subsubsection{Multi-variate Normal Distribution}
for independent r.v.s. $x_1, x_2, \ldots, x_n$ 
$$
p(\va*{x};\va*{\mu},\va*{\sigma}) = \prod_{i=1}^n p(x_i;\mu_i,\sigma_i) = \prod_{i=1}^n \frac{1}{\sqrt{2 \pi} \sigma_i} e^{-\frac{(x_i-\mu_i)^2}{2 \sigma_i^2}}
$$
with dependent r.v.s. have a correlation term:
$\va*{\sigma}$ = 
$$
\begin{pmatrix}
    \sigma_1^2 & \sigma_{12} & \sigma_{13} \\
    \sigma_{21} & \sigma_2^2 & \sigma_{23} \\
    \sigma_{31} & \sigma_{32} & \sigma_3^2 \\
\end{pmatrix}
$$
Terms in exp becomes
$(x-\mu)^T V^{-1} (x-\mu)$
\subsubsection{The exponential decay Distributions}
\subsubsection{Polynomial distributions}
\subsubsection{Chi-squared Distribution}
\subsubsection{Generating samples from distributions and the inverse c.d.f.}
using inverse c.d.f. to generate samples from distributions
or use accept and reject method
\subsection{Limit Theorems}
\subsubsection{Convergence}
\subsubsection{Central Limit Theorem}
\subsubsection{Errors}

\end{document}
